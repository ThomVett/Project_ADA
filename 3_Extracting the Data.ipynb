{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasvetterli/anaconda/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os, glob, string, re, datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Data\n",
    "Know that we have learned that we will not be able to process the data using a Spark pipeline, we will implement here a Python pipeline to read the files.\n",
    "\n",
    "## 1 - Extracting the paths\n",
    "\n",
    "We first have to get all the paths containing the XML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GDL = 'GDL'\n",
    "JDG = 'JDG'\n",
    "listFiles = []\n",
    "\n",
    "#Go through all the files of both journals\n",
    "for root, dirs, files in os.walk(GDL): \n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "             listFiles.append(os.path.join(root, file))\n",
    "\n",
    "for root, dirs, files in os.walk(JDG): \n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "             listFiles.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the path for each file in the dataset, we can work through each of them and count words. We will use the method described in **Filtering the Data.ipynb**\n",
    "\n",
    "## 2 - Extracting the word count\n",
    "Know that we have the paths for all text files, we can read the text and then clean it.\n",
    "\n",
    "First we need the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('french'))\n",
    "stop_words.extend(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']',\n",
    "                   '{', '}', '<', '>', '...', '-', '•', '/', '%', '«', '»', 'le',\n",
    "                  'les','..','©','plus','*','``','av','p.','fr','cette','a.','v.','b.','d.',\n",
    "                   'c.','e.','f.','i.','g.','h.','i.','j.','l.','m.','n.','o.','q.','r.','q.',\n",
    "                   's.','t.','u.','v.','w.','x.','z.','y.',\"d'un\",\"d'une\",'dm',\"c'est\",\n",
    "                   \"jusqu'au\",'entre','comme','si','di','„','&',\"qu'il\",'_','fd',\"n'a\",'alors',\n",
    "                   \"s'est\",\"n'est\",'cs','dès','où',\"jusqu'à\",'déjà',\"''\",'|','£','®','+','-«',\n",
    "                   '--','.-',\"la\",'---','-le','-n','î','â'])\n",
    "\n",
    "stop_words.extend(['','-.','.,','(,','»,',').','-.','av.','».',\n",
    "                      '....','..','...','.....','()','(r).','—',')-«',\n",
    "                      '\".','-,','(-.',')-.','(©','™','--','---','—•','•-',\n",
    "                  '•','••','•••','•••','—la','ï',\"'la\",'•—',\n",
    "                  '——','û','ê','ë','ù',\"'la\",'•—','——','—le',\"'''\",\"''\",\n",
    "                  \"'\",\"'le\",\"'la\",\"'i\",'-on',\"•'\",\"'-\",\"-'\",\"a'\",\"'de\",\"'la\",\n",
    "                  \"'â\",\"aa\",\"'-\",\"-de\",\"-et\",'-on','-les',',,,', '——•','•-•',\n",
    "                  '„„','•—•'])\n",
    "stop_words.extend(list(string.ascii_lowercase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And preparing the dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listPunct = list(string.punctuation)\n",
    "listPunct.remove(\"'\")\n",
    "listPunct.remove(\"-\")\n",
    "#we do not want to stick together all the words that\n",
    "#have an apostrophe (l'armée should not become larmée)\n",
    "stopDict = dict(zip(listPunct,['']*len(listPunct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a constant which tells us how many of the most frequenc words we take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numMostFreq = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can go through the list to extract the data in each file. We also set a counter to see how long it takes.\n",
    "\n",
    "We first extract the data in 43 different dataframes, otherwise the algorithm's complexity is too high and the process is endless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = len(listFiles)\n",
    "allText = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at : 0.0  %\n",
      "We are at : 2.306805074971165  %\n",
      "We are at : 4.61361014994233  %\n",
      "We are at : 6.920415224913495  %\n",
      "We are at : 9.22722029988466  %\n",
      "We are at : 11.534025374855824  %\n",
      "We are at : 13.84083044982699  %\n",
      "We are at : 16.147635524798154  %\n",
      "We are at : 18.45444059976932  %\n",
      "We are at : 20.761245674740483  %\n",
      "We are at : 23.06805074971165  %\n",
      "We are at : 25.37485582468281  %\n",
      "We are at : 27.68166089965398  %\n",
      "We are at : 29.988465974625143  %\n",
      "We are at : 32.29527104959631  %\n",
      "We are at : 34.602076124567475  %\n",
      "We are at : 36.90888119953864  %\n",
      "We are at : 39.21568627450981  %\n",
      "We are at : 41.522491349480966  %\n",
      "We are at : 43.82929642445214  %\n",
      "We are at : 46.1361014994233  %\n",
      "We are at : 48.44290657439446  %\n",
      "We are at : 50.74971164936562  %\n",
      "We are at : 53.05651672433679  %\n",
      "We are at : 55.36332179930796  %\n",
      "We are at : 57.67012687427913  %\n",
      "We are at : 59.976931949250286  %\n",
      "We are at : 62.28373702422145  %\n",
      "We are at : 64.59054209919262  %\n",
      "We are at : 66.89734717416378  %\n",
      "We are at : 69.20415224913495  %\n",
      "We are at : 71.51095732410612  %\n",
      "We are at : 73.81776239907728  %\n",
      "We are at : 76.12456747404845  %\n",
      "We are at : 78.43137254901961  %\n",
      "We are at : 80.73817762399077  %\n",
      "We are at : 83.04498269896193  %\n",
      "We are at : 85.35178777393311  %\n",
      "We are at : 87.65859284890428  %\n",
      "We are at : 89.96539792387543  %\n",
      "We are at : 92.2722029988466  %\n",
      "We are at : 94.57900807381776  %\n",
      "We are at : 96.88581314878893  %\n",
      "We are at : 99.19261822376009  %\n"
     ]
    }
   ],
   "source": [
    "for idx, file in enumerate(listFiles):   \n",
    "    #counter \n",
    "    counter(idx)\n",
    "    #find the date at which the article is published.\n",
    "    date = pd.to_datetime(file[4:11])\n",
    "    #Open the XML\n",
    "    f = open(file,'r')\n",
    "    soupArticle = BeautifulSoup(f,'lxml')\n",
    "    f.close()\n",
    "    \n",
    "    #Extracting the entire text from the XML\n",
    "    Article = []\n",
    "    for ft in soupArticle.find_all('full_text'):\n",
    "        #Here we lower each words and we remove the numbers from the text\n",
    "        Article.append(re.sub(r'\\d+', '', ft.text).lower())\n",
    "\n",
    "    textArticle = ' '.join(Article)  \n",
    "    \n",
    "    #Cleaning and counting\n",
    "    for k,v in stopDict.items():\n",
    "        textArticle = textArticle.replace(k,v)\n",
    "\n",
    "    dictCounter = [wordsDict for wordsDict in textArticle.split(' ') if wordsDict not in stop_words]\n",
    "    countDict = Counter(dictCounter).most_common(numMostFreq)\n",
    "    \n",
    "    #Transofming to a dataframe\n",
    "    df = pd.DataFrame(countDict).transpose()\n",
    "    df.columns = df.loc[0]\n",
    "    df.drop(0,inplace=True)\n",
    "    df.index = [date]\n",
    "    allText.append(df)\n",
    "    \n",
    "    if idx > 0:\n",
    "        if idx%106 == 0:\n",
    "            dfAllText = pd.concat(allText,axis=0)\n",
    "            dfAllText.to_csv('Data/Part_'+str(idx)+'.csv')\n",
    "            del allText\n",
    "            allText = []\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abfens</th>\n",
       "      <th>abfolument</th>\n",
       "      <th>abus</th>\n",
       "      <th>accepte</th>\n",
       "      <th>accepté</th>\n",
       "      <th>acceptée</th>\n",
       "      <th>accorde</th>\n",
       "      <th>accordé</th>\n",
       "      <th>actifs</th>\n",
       "      <th>actions</th>\n",
       "      <th>...</th>\n",
       "      <th>éprouve</th>\n",
       "      <th>éprouvé</th>\n",
       "      <th>établi</th>\n",
       "      <th>état</th>\n",
       "      <th>étoit</th>\n",
       "      <th>évacué</th>\n",
       "      <th>événemens</th>\n",
       "      <th>événement</th>\n",
       "      <th>être</th>\n",
       "      <th>île</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1799-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799-07-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>154</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799-08-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>185</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799-09-01</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>112</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799-10-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           abfens abfolument abus accepte accepté acceptée accorde accordé  \\\n",
       "1799-06-01    NaN        NaN  NaN      17     NaN      NaN       9      11   \n",
       "1799-07-01    NaN         10    8      15     NaN      NaN     NaN      10   \n",
       "1799-08-01    NaN        NaN    9      13      10      NaN     NaN     NaN   \n",
       "1799-09-01      8          8  NaN      14       8        9     NaN     NaN   \n",
       "1799-10-01    NaN         10  NaN      13     NaN       10     NaN     NaN   \n",
       "\n",
       "           actifs actions ...  éprouve éprouvé établi état étoit évacué  \\\n",
       "1799-06-01    NaN     NaN ...      NaN     NaN     14   16     7    NaN   \n",
       "1799-07-01    NaN       8 ...      NaN     NaN     10   23   NaN    NaN   \n",
       "1799-08-01    NaN     NaN ...      NaN     NaN    NaN   25   NaN    NaN   \n",
       "1799-09-01      8     NaN ...      NaN     NaN    NaN   19   NaN    NaN   \n",
       "1799-10-01    NaN     NaN ...        8       8     12   34     9      9   \n",
       "\n",
       "           événemens événement être  île  \n",
       "1799-06-01       NaN         7  114    9  \n",
       "1799-07-01       NaN        12  154   10  \n",
       "1799-08-01       NaN         9  185   12  \n",
       "1799-09-01       NaN        11  112    8  \n",
       "1799-10-01         9        13  103  NaN  \n",
       "\n",
       "[5 rows x 1737 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAllText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the separate dataframes we can implement a function to concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvFiles = []\n",
    "\n",
    "for root, dirs, files in os.walk('Data'): \n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "             csvFiles.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for the extractions\n",
    "\n",
    "Just a short function that was used to track the progress of the data extraction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counter(i):\n",
    "    if i%100==0:\n",
    "        print('We are at :', i/total*100 ,' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listDF = []\n",
    "for idx, item in enumerate(csvFiles):\n",
    "    listDF.append(pd.read_csv(item,index_col=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the separate dataFrames, we can take a look at the first version of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>''''</th>\n",
       "      <th>'''''</th>\n",
       "      <th>''''''</th>\n",
       "      <th>''-</th>\n",
       "      <th>''»</th>\n",
       "      <th>''•</th>\n",
       "      <th>'-'</th>\n",
       "      <th>'--</th>\n",
       "      <th>'a</th>\n",
       "      <th>'aisi</th>\n",
       "      <th>...</th>\n",
       "      <th>—•—</th>\n",
       "      <th>—•—•</th>\n",
       "      <th>•«</th>\n",
       "      <th>•»</th>\n",
       "      <th>•—•—</th>\n",
       "      <th>••'</th>\n",
       "      <th>••••</th>\n",
       "      <th>•••••</th>\n",
       "      <th>••••••</th>\n",
       "      <th>€</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1798-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-03-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32412 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ''''  '''''  ''''''  ''-  ''»  ''•  '-'  '--  'a  'aisi ...  —•—  \\\n",
       "1798-02-01   NaN    NaN     NaN  NaN  NaN  NaN  NaN  NaN NaN    NaN ...  NaN   \n",
       "1798-03-01   NaN    NaN     NaN  NaN  NaN  NaN  NaN  NaN NaN    NaN ...  NaN   \n",
       "1798-04-01   NaN    NaN     NaN  NaN  NaN  NaN  NaN  NaN NaN    NaN ...  NaN   \n",
       "1798-05-01   NaN    NaN     NaN  NaN  NaN  NaN  NaN  NaN NaN    NaN ...  NaN   \n",
       "1798-06-01   NaN    NaN     NaN  NaN  NaN  NaN  NaN  NaN NaN    NaN ...  NaN   \n",
       "\n",
       "            —•—•  •«  •»  •—•—  ••'  ••••  •••••  ••••••   €  \n",
       "1798-02-01   NaN NaN NaN   NaN  NaN   NaN    NaN     NaN NaN  \n",
       "1798-03-01   NaN NaN NaN   NaN  NaN   NaN    NaN     NaN NaN  \n",
       "1798-04-01   NaN NaN NaN   NaN  NaN   NaN    NaN     NaN NaN  \n",
       "1798-05-01   NaN NaN NaN   NaN  NaN   NaN    NaN     NaN NaN  \n",
       "1798-06-01   NaN NaN NaN   NaN  NaN   NaN    NaN     NaN NaN  \n",
       "\n",
       "[5 rows x 32412 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDF = pd.concat(listDF,axis=0)\n",
    "finalDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The first conclusion is that despite our cleaning process there are still a lot of symbols that were kept that we do not need. For example strings that contained the \"-\" symbol were not erased because we wanted to keep other words such as week-end. \n",
    "\n",
    "To begin working with the data we first have to do some cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "\n",
    "First, we delete the column with the useless symbols. We manually check which columns have to be dropped! We also fill each NaN value as a 0, to be able to work with words that are absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalDF = finalDF.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>''''</th>\n",
       "      <th>'''''</th>\n",
       "      <th>''''''</th>\n",
       "      <th>''-</th>\n",
       "      <th>''»</th>\n",
       "      <th>''•</th>\n",
       "      <th>'-'</th>\n",
       "      <th>'--</th>\n",
       "      <th>'a</th>\n",
       "      <th>'aisi</th>\n",
       "      <th>...</th>\n",
       "      <th>a'court</th>\n",
       "      <th>a-</th>\n",
       "      <th>a-c</th>\n",
       "      <th>a-k</th>\n",
       "      <th>a-l-il</th>\n",
       "      <th>a-t</th>\n",
       "      <th>a-t-</th>\n",
       "      <th>a-t-il</th>\n",
       "      <th>a-t-on</th>\n",
       "      <th>aaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1798-02-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-03-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-04-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-06-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ''''  '''''  ''''''  ''-  ''»  ''•  '-'  '--   'a  'aisi ...   \\\n",
       "1798-02-01   0.0    0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0 ...    \n",
       "1798-03-01   0.0    0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0 ...    \n",
       "1798-04-01   0.0    0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0 ...    \n",
       "1798-05-01   0.0    0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0 ...    \n",
       "1798-06-01   0.0    0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0 ...    \n",
       "\n",
       "            a'court   a-  a-c  a-k  a-l-il  a-t  a-t-  a-t-il  a-t-on  aaa  \n",
       "1798-02-01      0.0  0.0  0.0  0.0     0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "1798-03-01      0.0  0.0  0.0  0.0     0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "1798-04-01      0.0  0.0  0.0  0.0     0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "1798-05-01      0.0  0.0  0.0  0.0     0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "1798-06-01      0.0  0.0  0.0  0.0     0.0  0.0   0.0     0.0     0.0  0.0  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDF.ix[:,0:236].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaland</th>\n",
       "      <th>aalen</th>\n",
       "      <th>aap</th>\n",
       "      <th>aar</th>\n",
       "      <th>aarau</th>\n",
       "      <th>aarberg</th>\n",
       "      <th>aax</th>\n",
       "      <th>aay</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab-intestat</th>\n",
       "      <th>...</th>\n",
       "      <th>—•—</th>\n",
       "      <th>—•—•</th>\n",
       "      <th>•«</th>\n",
       "      <th>•»</th>\n",
       "      <th>•—•—</th>\n",
       "      <th>••'</th>\n",
       "      <th>••••</th>\n",
       "      <th>•••••</th>\n",
       "      <th>••••••</th>\n",
       "      <th>€</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1798-02-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-03-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-04-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798-06-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaland  aalen  aap  aar  aarau  aarberg  aax  aay   ab  \\\n",
       "1798-02-01     0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0   \n",
       "1798-03-01     0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0   \n",
       "1798-04-01     0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0   \n",
       "1798-05-01     0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0   \n",
       "1798-06-01     0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0  0.0   \n",
       "\n",
       "            ab-intestat ...   —•—  —•—•   •«   •»  •—•—  ••'  ••••  •••••  \\\n",
       "1798-02-01          0.0 ...   0.0   0.0  0.0  0.0   0.0  0.0   0.0    0.0   \n",
       "1798-03-01          0.0 ...   0.0   0.0  0.0  0.0   0.0  0.0   0.0    0.0   \n",
       "1798-04-01          0.0 ...   0.0   0.0  0.0  0.0   0.0  0.0   0.0    0.0   \n",
       "1798-05-01          0.0 ...   0.0   0.0  0.0  0.0   0.0  0.0   0.0    0.0   \n",
       "1798-06-01          0.0 ...   0.0   0.0  0.0  0.0   0.0  0.0   0.0    0.0   \n",
       "\n",
       "            ••••••    €  \n",
       "1798-02-01     0.0  0.0  \n",
       "1798-03-01     0.0  0.0  \n",
       "1798-04-01     0.0  0.0  \n",
       "1798-05-01     0.0  0.0  \n",
       "1798-06-01     0.0  0.0  \n",
       "\n",
       "[5 rows x 32176 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFClean_0 = finalDF.drop(finalDF.columns[0:236],axis=1)\n",
    "DFClean_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DFClean_1 = DFClean_0.drop(DFClean_0.columns[32090:32176],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed the columns with unnecessary symbols, we still have to group by month, as we had articles for two journals, that we have to group together as they were published during the same month / year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GroupYear = DFClean_1.groupby(DFClean_1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCountYear = GroupYear.agg(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is not yet in datetime format, we need it to be to plot values as time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCountYear.index = pd.to_datetime(wordCountYear.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we save the data in a csv file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCountYear.to_csv('Data/wordCountYear.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
