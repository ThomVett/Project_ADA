{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "\n",
    "Now that we have seen what our datset looked like, we have to a little bit of cleaning. There are three main tasks:\n",
    "1. Removing two letter words that make no sense\n",
    "2. Taking care of plural and singular, and merge them\n",
    "3. Merge words that are similar, i.e having the same root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordCountYear = pd.read_csv('Data/3kwordCountMonth.csv',index_col=0)\n",
    "wordCountYear.index = pd.to_datetime(wordCountYear.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The columns that begin by '-'\n",
    "\n",
    "Because we wanted to keep words such as week-end, we have a certain number of columns that start with '-' and a word, we will remove the dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnNames = wordCountYear.columns.map(lambda x: x[1:] if str(x).startswith('-') else x)\n",
    "wordCountYear.columns = columnNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And the words that end with dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otherName = wordCountYear.columns.map(lambda x: x[1:] if str(x).endswith('-') else x)\n",
    "wordCountYear.columns = otherName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can group by the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4351, 77595)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountMonthClean1 =  wordCountYear.groupby(by=wordCountYear.columns,axis=1,level=0).agg(sum)\n",
    "wordCountMonthClean1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with adverbs\n",
    "\n",
    "We will group words with theit adverb (word and word + ement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adverbs = wordCountMonthClean1.columns.map(lambda x: x[:-5] if str(x).endswith('ement') else x)\n",
    "wordCountMonthClean1.columns = adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4351, 77458)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountMontClean2 = wordCountMonthClean1.groupby(by=wordCountYear.columns,axis=1,level=0).agg(sum)\n",
    "wordCountMontClean2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging singular and plural words\n",
    "\n",
    "As we were not satisfied by the NLTK work on the french language, we will implement our own small algorithm to merge similar words together. We start were merging singular and plural words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the words\n",
    "columnNames = wordCountMontClean2.columns.map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look up a few of the column titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abbatemaggio', 'abbatiale', 'abbatucci', 'abbaye', 'abbayes',\n",
       "       'abbazia', 'abbesse', 'abbet', 'abbeville', 'abbey', 'abbie',\n",
       "       'abbot', 'abbott', 'abboud', 'abbruzzes', 'abbé', 'abbés', 'abc',\n",
       "       'abchases', 'abcès'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnNames[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the plural of a word comes normally just after it's singular, we therefore do not have to check all of the other words for plurals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Singular-Plural word pairs :  7125\n",
      "['abandonné', 'abandonnée', 'abattoir', 'abattu', 'abattue', 'abbaye', 'abbé']\n",
      "['abandonnés', 'abandonnées', 'abattoirs', 'abattus', 'abattues', 'abbayes', 'abbés']\n"
     ]
    }
   ],
   "source": [
    "sing = []\n",
    "plural = []\n",
    "for i in range(len(columnNames)):\n",
    "    col = columnNames[i]\n",
    "    colPlur = col+'s'\n",
    "    colPlurX = col+'x'\n",
    "    if (i+5) > (len(columnNames) - 1):\n",
    "        lastEl =  len(columnNames) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    for plur in columnNames[i:lastEl]:\n",
    "        if (colPlur == plur) or (colPlurX == plur):\n",
    "            sing.append(col)\n",
    "            plural.append(plur)\n",
    "\n",
    "print('Number of Singular-Plural word pairs : ', len(dict(zip(sing,plural))))\n",
    "#We have to remove the jouis and jouiss pairs because, jouis will already be removed with the joui pair\n",
    "#pluralWords.pop(1329)\n",
    "singPlurDict = dict(zip(plural,sing))\n",
    "print(sing[:7])\n",
    "print(plural[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that we can replace the column names and then groupby so that we merge the data from the two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordCountMontClean2.rename(columns = singPlurDict,inplace=True)\n",
    "cleanData = wordCountMontClean2.groupby(by=wordCountMontClean2.columns,axis=1,level=0).agg(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the masculine and feminine version of words and of the verbs and their infinitif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newCol = cleanData.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fem singular, verbs word pairs :  3760\n",
      "['abandonne', 'abandonné', 'abattu', 'abl', 'aboli', 'aboli', 'abondant']\n",
      "['abandonner', 'abandonnée', 'abattue', 'able', 'abolie', 'abolir', 'abondante']\n"
     ]
    }
   ],
   "source": [
    "fem = []\n",
    "masc = []\n",
    "\n",
    "for i in range(len(newCol)):\n",
    "    col = newCol[i]\n",
    "    colfem= col+'e'\n",
    "    infVerb = col+'r'\n",
    "    if (i+5) > (len(newCol) - 1):\n",
    "        lastEl =  len(newCol) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    for plur in newCol[i:lastEl]:\n",
    "        if (colfem == plur) or (infVerb == plur):\n",
    "            masc.append(col)\n",
    "            fem.append(plur)\n",
    "\n",
    "dictFM = dict(zip(masc,fem))\n",
    "print('Number of fem singular, verbs word pairs : ', len(dictFM))\n",
    "print(masc[:7])\n",
    "print(fem[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we groupby again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanData.rename(columns = dictFM,inplace=True)\n",
    "cleanData1 = cleanData.groupby(by=cleanData.columns,axis=1,level=0).agg(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fem singular, verbs word pairs :  441\n",
      "['actuell', 'adapté', 'adjoint', 'adjugé', 'administré', 'admirabl', 'admire']\n",
      "['actuelle', 'adaptée', 'adjointe', 'adjugée', 'administrée', 'admirable', 'admirer']\n"
     ]
    }
   ],
   "source": [
    "verb = []\n",
    "conj = []\n",
    "\n",
    "for i in range(len(cleanData1.columns)):\n",
    "    col = cleanData1.columns[i]\n",
    "    infVerb = col[:-1]+'er'\n",
    "    if (i+5) > (len(cleanData1.columns) - 1):\n",
    "        lastEl =  len(cleanData1.columns) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    for plur in cleanData1.columns[i:lastEl]:\n",
    "        if (infVerb == plur):\n",
    "            verb.append(col)\n",
    "            conj.append(plur)\n",
    "\n",
    "dictVC = dict(zip(verb,conj))\n",
    "print('Number of fem singular, verbs word pairs : ', len(dictVC))\n",
    "print(masc[50:57])\n",
    "print(fem[50:57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData1.rename(columns = dictVC,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to replace \"participe passé\" feminine to the infinitif verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['abandonnée', 'abritée', 'abrogée', 'abrégée', 'accentuée', 'acceptée',\n",
      "       'accompagnée', 'accordée', 'accouchée', 'accoutumée',\n",
      "       ...\n",
      "       'éloignée', 'éprouvée', 'épuisée', 'épée', 'équipée', 'étonnée',\n",
      "       'étouffée', 'étudiée', 'évacuée', 'évaluée'],\n",
      "      dtype='object', length=792)\n"
     ]
    }
   ],
   "source": [
    "print(cleanData1.columns[np.chararray.endswith(cleanData1.columns.values.astype(str),'ée')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData1.columns = cleanData1.columns.map(lambda x: x[:-2]+'er' if str(x).endswith('ée') else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And then we can groupby again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4351, 65942)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData2 = cleanData1.groupby(by=cleanData1.columns,axis=1,level=0).agg(sum)\n",
    "cleanData2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our dataset is still very large, but those operations manage to reduce its size without loosing information!\n",
    "\n",
    "Now that we have tried not to loose too much of information by trying to merge words that have the same meaning we can start doing some more direct actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "One of the problem that we have for our dataset is that there are some months were a word count is missing (for some words). When importing the data we had to choose a frequency limit, and we did not save words that appeared below this limit. Due to the long tail distribution of the data words that have a fequency near the limit can be above it in one month and below it in the other month, therefore we will have a lot of missing values for this word.\n",
    "\n",
    "For furutre predictions and visualization we are more interested in the general shape of the time series, and not the few months in between where the word is missing, therefore it could be interesting to interpolate the missing data.\n",
    "\n",
    "But there are also words that are only in present only in a few months and not more. We do not need these words as they are not interesting to predict and do not bring an interesting visualizations.\n",
    "\n",
    "Due to the fact that we have made some aggregations in the previous steps, we assume that removing words that do not occur very often will not loose information about the other words. We choose to remove words that only appear in 10 different months or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData3 = cleanData2.copy()\n",
    "numMonth = cleanData3.astype(bool).sum(axis=0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at which words are in this situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a-été', 'aaaa', 'aaaactions', 'aaat', 'aac', 'aach', 'aacom', 'aae',\n",
       "       'aal', 'aalandais', 'aalborg', 'aalen', 'aalesund', 'aali-pacha', 'aan',\n",
       "       'aandoz', 'aar-tessin', 'aara', 'aarbourg', 'aardman', 'aargau',\n",
       "       'aargauerstalden', 'aarmiihle', 'aarvan', 'aarwangen', 'aarwanguen',\n",
       "       'aasan', 'aassi', 'aasta', 'aat', 'aatre', 'ab-y-berg', 'aba',\n",
       "       'abadessa', 'abadie', 'abaisser', 'abaissé', 'abakanowicz', 'abako',\n",
       "       'abandonnait', 'abandonnent', 'abanico', 'abanto', 'abanville',\n",
       "       'abarth', 'abarzuza', 'abatage', 'abatt', 'abattage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData3.columns[numMonth<10][1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alboni', 'alboraya', 'albos', 'albrighi', 'albright', 'albu', 'albula',\n",
       "       'albumine', 'albéniz', 'albéric', 'alcalins', 'alcaloïdes', 'alcantara',\n",
       "       'alcat', 'alceste', 'alcibiade', 'alcide', 'alcman', 'alco', 'alcolea',\n",
       "       'alcon', 'alcoy', 'alcudia', 'alcyon', 'aldanska', 'aldaux',\n",
       "       'aldeacorba', 'aldebert', 'alden', 'alderman', 'aldermen', 'aldersley',\n",
       "       'aldewin', 'aldonza', 'aldous', 'aldrin', 'aldsi', 'aldy', 'alecha',\n",
       "       'alechinsky', 'aleck', 'aleko', 'aleko-pacha', 'aleman', 'alembert',\n",
       "       'alena', 'alentejo', 'alentours', 'alençon', 'alermillod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData3.columns[numMonth<10][700:750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before the cleaning:  (4351, 65942)\n",
      "After the cleaning:  (4351, 23873)\n"
     ]
    }
   ],
   "source": [
    "print('Before the cleaning: ', cleanData3.shape)\n",
    "cleanData3.drop(cleanData3.columns[numMonth < 10].values,axis=1,inplace=True)\n",
    "print('After the cleaning: ', cleanData3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can save the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanData3.to_csv('Data/wordMonthClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
