{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "\n",
    "Now that we have seen what our datset looked like, we have to a little bit of cleaning. There are three main tasks:\n",
    "1. Removing two letter words that make no sense\n",
    "2. Taking care of plural and singular, and merge them\n",
    "3. Merge words that are similar, i.e having the same root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordCountYear = pd.read_csv('Data/3kwordCountMonth.csv',index_col=0)\n",
    "wordCountYear.index = pd.to_datetime(wordCountYear.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The columns that begin by '-'\n",
    "\n",
    "Because we wanted to keep words such as week-end, we have a certain number of columns that start with '-' and a word, we will remove the dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columnNames = wordCountYear.columns.map(lambda x: x[1:] if str(x).startswith('-') else x)\n",
    "wordCountYear.columns = columnNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And the words that end with dash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otherName = wordCountYear.columns.map(lambda x: x[1:] if str(x).endswith('-') else x)\n",
    "wordCountYear.columns = otherName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can group by the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4351, 77595)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountMonthClean1 =  wordCountYear.groupby(by=wordCountYear.columns,axis=1,level=0).agg(sum)\n",
    "wordCountMonthClean1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with adverbs\n",
    "\n",
    "We will group words with theit adverb (word and word + ement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adverbs = wordCountMonthClean1.columns.map(lambda x: x[:-5] if str(x).endswith('ement') else x)\n",
    "wordCountMonthClean1.columns = adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4351, 77458)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountMontClean2 = wordCountMonthClean1.groupby(by=wordCountYear.columns,axis=1,level=0).agg(sum)\n",
    "wordCountMontClean2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging singular and plural words\n",
    "\n",
    "As we were not satisfied by the NLTK work on the french language, we will implement our own small algorithm to merge similar words together. We start were merging singular and plural words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the words\n",
    "columnNames = wordCountYear.columns.map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look up a few of the column titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['académique', 'académiques', 'accent', 'accepte', 'accepter',\n",
       "       'acceptions', 'accepté', 'acceptée', 'accessils', 'accessit',\n",
       "       'accessits', 'accessoires', 'accidens', 'accident', 'accidents',\n",
       "       'acclamations', 'accompagnemens', 'accompagnement', 'accompagnent',\n",
       "       'accompagné'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnNames[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the plural of a word comes normally just after it's singular, we therefore do not have to check all of the other words for plurals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Singular-Plural word pairs :  2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['abeille', 'abeilles'],\n",
       " ['abolie', 'abolies'],\n",
       " ['abondante', 'abondantes'],\n",
       " ['abonnement', 'abonnements'],\n",
       " ['abord', 'abords'],\n",
       " ['abraham', 'abrahams'],\n",
       " ['absolu', 'absolus'],\n",
       " ['abyssin', 'abyssins'],\n",
       " ['acacia', 'acacias']]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluralWords = []\n",
    "\n",
    "for i in range(len(columnNames)):\n",
    "    wordPair = []\n",
    "    col = columnNames[i]\n",
    "    colPlur = col+'s'\n",
    "    if (i+5) > (len(columnNames) - 1):\n",
    "        lastEl =  len(columnNames) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    for plur in columnNames[i:lastEl]:\n",
    "        if colPlur == plur:\n",
    "            wordPair.append(col)\n",
    "            wordPair.append(plur)\n",
    "            pluralWords.append(wordPair)  \n",
    "\n",
    "print('Number of Singular-Plural word pairs : ', len(pluralWords))\n",
    "#We have to remove the jouis and jouiss pairs because, jouis will already be removed with the joui pair\n",
    "pluralWords.pop(1329)\n",
    "pluralWords[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can see that our algorithm work we have to merge together our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2683/2683 [59:12<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "testMerge = wordCountYear.copy()\n",
    "for i in tqdm(range(len(pluralWords))):\n",
    "    wordSum = wordCountYear[pluralWords[i]].sum(axis=1)\n",
    "    #deleting the columns\n",
    "    testMerge.drop(pluralWords[i],axis=1,inplace=True)\n",
    "    testMerge[pluralWords[i][0]] = wordSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2353, 28908)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testMerge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our dataset is still very large, but those operations manage to reduce its size without loosing information!\n",
    "\n",
    "We were not able to find a good function to group together words of the same group, so we tried to merge together other plurals (with x at the end, and gender words that we can put together. We also remark that we have to look at words that are longer than 3 letters because otherwise we merge too many words that make no sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanCol1 = testMerge.columns.map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noël noële\n"
     ]
    }
   ],
   "source": [
    "#Here we try to group together words that are in the text in the masculine and feminine version.\n",
    "family = []\n",
    "for i in range(len(cleanCol1)):\n",
    "    wordFamily = []\n",
    "    col = testMerge.columns.values[i]\n",
    "    if (i+5) > (len(columnNames) - 1):\n",
    "        lastEl =  len(columnNames) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    i=0\n",
    "    colPlur = col+'e'\n",
    "    for plur in cleanCol1[i+1:lastEl]:\n",
    "        if (colPlur == plur) & (len(col) > 3):\n",
    "            wordFamily.append(col)\n",
    "            wordFamily.append(plur)\n",
    "            family.append(wordFamily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at a few of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['augmenté', 'augmentée'],\n",
       " ['austro-hongrois', 'austro-hongroise'],\n",
       " ['autrich', 'autriche'],\n",
       " ['avis', 'avise'],\n",
       " ['band', 'bande'],\n",
       " ['bard', 'barde'],\n",
       " ['bart', 'barte'],\n",
       " ['barth', 'barthe'],\n",
       " ['benoît', 'benoîte'],\n",
       " ['berlinois', 'berlinoise'],\n",
       " ['bertaud', 'bertaude'],\n",
       " ['black', 'blacke'],\n",
       " ['bossu', 'bossue'],\n",
       " ['boug', 'bouge'],\n",
       " ['bourgeois', 'bourgeoise']]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family[20:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for some words we have the masculine and feminine version, but other it is just the word that has a spelling mistake, so for spelling purposes we will take the feminine version for the grouping and the final word.\n",
    "\n",
    "Now let's look at plurals finishing with x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['drapeau', 'drapeaux'],\n",
       " ['fceau', 'fceaux'],\n",
       " ['fourneau', 'fourneaux'],\n",
       " ['genou', 'genoux'],\n",
       " ['hameau', 'hameaux'],\n",
       " ['journau', 'journaux'],\n",
       " ['manteau', 'manteaux'],\n",
       " ['marsan', 'marsanx'],\n",
       " ['merck', 'merckx'],\n",
       " ['milieu', 'milieux'],\n",
       " ['morceau', 'morceaux'],\n",
       " ['morne', 'mornex'],\n",
       " ['neveu', 'neveux'],\n",
       " ['nouveau', 'nouveaux'],\n",
       " ['peau', 'peaux']]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we try to group together words that are in the text in the masculine and feminine version.\n",
    "plurX = []\n",
    "for i in range(len(cleanCol1)):\n",
    "    pluxXfamily = []\n",
    "    col = testMerge.columns.values[i]\n",
    "    if (i+5) > (len(columnNames) - 1):\n",
    "        lastEl =  len(columnNames) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    i=0\n",
    "    colPlur = col+'x'\n",
    "    for plur in cleanCol1[i+1:lastEl]:\n",
    "        if (colPlur == plur) & (len(col) > 3):\n",
    "            pluxXfamily.append(col)\n",
    "            pluxXfamily.append(plur)\n",
    "            plurX.append(pluxXfamily)\n",
    "            if col == 'noël':\n",
    "                print(col,plur)\n",
    "    \n",
    "plurX[10:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have words that we can merge together , we will work to combine our dataset again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 553/553 [11:01<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "cleanData1 = testMerge.copy()\n",
    "for i in tqdm(range(len(family))):\n",
    "    wordSum = cleanData1[family[i]].sum(axis=1)\n",
    "    #deleting the columns\n",
    "    cleanData1.drop(family[i],axis=1,inplace=True)\n",
    "    cleanData1[family[i][1]] = wordSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we take care of the plural words with x!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:53<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "cleanData2 = cleanData1.copy()\n",
    "for i in tqdm(range(len(plurX))):\n",
    "    wordSum = cleanData2[plurX[i]].sum(axis=1)\n",
    "    #deleting the columns\n",
    "    cleanData2.drop(plurX[i],axis=1,inplace=True)\n",
    "    cleanData2[plurX[i][0]] = wordSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we save the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanData2.to_csv('wordCount_Clean_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reimporting to continue working with data\n",
    "cleanData2 = pd.read_csv('wordCount_Clean_v1.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking care of apostrophes\n",
    "One issue that we did not take care during the extraction of the data is that we did not remove apostrophe from the dataset (which we should have). We therefore want to remove them now to group together the word that was alone with the word with an apostrophe, for example l'état and état should be counted together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding which column titles contain an apostrophe\n",
    "isApostrophe = cleanData2.columns.astype(str).map(lambda x: len(x.split(\"'\")))\n",
    "separation = cleanData2.columns.astype(str).map(lambda x: x.split(\"'\"))\n",
    "\n",
    "#we need a dict for the new columns\n",
    "newName = dict(zip(cleanData2.columns[isApostrophe==2],\n",
    "                   [e[1] for e in separation[isApostrophe==2]]))\n",
    "\n",
    "cleanData2.rename(columns = newName,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can groupBy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData2 = cleanData2.groupby(by=cleanData2.columns,axis=1,level=0).agg(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have not yet taken care of vers (that finish with er)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colNamesClean2 = cleanData2.columns.values\n",
    "verb = []\n",
    "infinitif = []\n",
    "masc = []\n",
    "fem = []\n",
    "for i in range(len(colNamesClean2)):\n",
    "    col = colNamesClean2[i]\n",
    "    if (i+5) > (len(colNamesClean2) - 1):\n",
    "        lastEl =  len(colNamesClean2) - 1\n",
    "    else:\n",
    "        lastEl = i+5\n",
    "    \n",
    "    colPlur = col+'r'\n",
    "    colPlurE = col+'e'\n",
    "    for plur in colNamesClean2[i+1:lastEl]:\n",
    "        if (colPlur == plur):\n",
    "            verb.append(col)\n",
    "            infinitif.append(plur)\n",
    "\n",
    "        if(colPlurE == plur):\n",
    "            masc.append(col)\n",
    "            fem.append(plur)\n",
    "        \n",
    "\n",
    "dictMF = dict(zip(fem,masc))\n",
    "dictVerb = dict(zip(verb,infinitif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we use this new dict to map new columns, just as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData2.rename(columns = dictVerb,inplace=True)\n",
    "cleanData2.rename(columns = dictMF,inplace=True)\n",
    "cleanData2 = cleanData2.groupby(by=cleanData2.columns,axis=1,level=0).agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2353, 26481)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanData2.to_csv('wordCount_Clean_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have already been able to reduce the number of words by nearly 1/6 without loosing word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "One of the problem that we have for our dataset is that there are some months were a word count is missing (for some words). If we look at the general trend (for example week-end), we can assume that it is not week-end that has fallen out of interest in the journals. It's possible that we had a problem in the data acquisition. For furutre predition and visualization we are more interested in the general shape of the time series, and not the few months in between where the word is missing, therefore it could be interesting to interpolate the missing data.\n",
    "\n",
    "Before interpolating we can start removing words that were present only in 3 month or less and nowhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData3 = cleanData2.copy()\n",
    "numMonth = cleanData3.astype(bool).sum(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleanData3.drop(cleanData3.columns[numMonth < 4].values,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at how many times each word is present, and we remove the words that are only present less than 30 times. As words follow a long tail distribution, most of them will not appear very often it's hard to remove words without being scared to loose too much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totNumWords = cleanData3.sum(axis=0).values\n",
    "cleanData3.drop(cleanData3.columns[totNumWords<25].values,axis=1,inplace=True)\n",
    "cleanData3.rename(columns = {'noële' : 'noël'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleanData3.to_csv('wordCountYear_Clean_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
