{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from bs4 import BeautifulSoup\n",
    "import re,nltk,string,datetime\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data\n",
    "\n",
    "Each XML file containing lots of text that is not very relevant we have first to filter it.\n",
    "\n",
    "We will first try several approaches to find which one runs the fastest.\n",
    "\n",
    "For all of them the first part is to extract the text data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('1996/07.xml','r')\n",
    "soupArticle = BeautifulSoup(f,'lxml')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Article = []\n",
    "for ft in soupArticle.find_all('full_text'):\n",
    "    #Here we lower each words and we remove the numbers from the text\n",
    "    Article.append(re.sub(r'\\d+', '', ft.text).lower())\n",
    "\n",
    "textArticle = ' '.join(Article)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first aproach we try is by using nltk and word tokenization.\n",
    "\n",
    "First we take care of the stopwords. We have to begin to manually update the french stopword list because it misses a lot of words that are not important for the analysis. There are also letters that we have to add because there are parts of the XML that contain really random stuff and gives bizarre results in the counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('french'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']',\n",
    "                   '{', '}', '<', '>', '...', '-', '•', '/', '%', '«', '»', 'le',\n",
    "                  'les','..','©','plus','*','``','av','p.','fr','cette','a.','v.','b.','d.',\n",
    "                   'c.','e.','f.','i.','g.','h.','i.','j.','l.','m.','n.','o.','q.','r.','q.',\n",
    "                   's.','t.','u.','v.','w.','x.','z.','y.',\"d'un\",\"d'une\",'dm',\"c'est\",\n",
    "                   \"jusqu'au\",'entre','comme','si','di','„','&',\"qu'il\",'_','fd',\"n'a\",'alors',\n",
    "                   \"s'est\",\"n'est\",'cs','dès','où',\"jusqu'à\",'déjà',\"''\",'|','£','®','+','-«',\n",
    "                   '--','.-'])\n",
    "\n",
    "#there are some random letters and we do not want to keep them in our \n",
    "#word count\n",
    "stop_words.update(set(string.whitespace))\n",
    "stop_words.update(set(string.ascii_lowercase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test to see how long it takes with nltk FreqDist and compare it with the counting \n",
    "from Collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokensArticle = nltk.word_tokenize(textArticle)\n",
    "ArticleNltk = nltk.Text(tokensArticle)\n",
    "textArticleClean = [i.lower() for i in ArticleNltk if i.lower() not in stop_words]\n",
    "frequentArticle = nltk.FreqDist(textArticleClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ans', 740),\n",
       " ('suisse', 449),\n",
       " ('deux', 282),\n",
       " ('genève', 276),\n",
       " ('fait', 202),\n",
       " ('sans', 202),\n",
       " ('tout', 198),\n",
       " ('juin', 183)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countFreq = frequentArticle.most_common(1000)\n",
    "countFreq[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokensArticle = nltk.word_tokenize(textArticle)\n",
    "ArticleNltk = nltk.Text(tokensArticle)\n",
    "textArticleClean = [i.lower() for i in ArticleNltk if i.lower() not in stop_words]\n",
    "textClean = ' '.join(textArticleClean)\n",
    "countCounter = Counter(textClean.split()).most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ans', 740),\n",
       " ('suisse', 449),\n",
       " ('deux', 282),\n",
       " ('genève', 276),\n",
       " ('fait', 202),\n",
       " ('sans', 202),\n",
       " ('tout', 198),\n",
       " ('juin', 183)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countCounter[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using nltk we see that both counting approaches give the same results. Now we will try without using NLTK and just filtering the text, which is normal the main point of this test was to see if Collections.Counter would be faster than nltk.FreqDist.\n",
    "\n",
    "We will also test a brute force approach by working directly with the text string.\n",
    "\n",
    "We first begin by creating a list containing the stop words, which we will use to clean the text from undesired characters. For that we can use the stop words from nltk as well as our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listArticle = textArticle\n",
    "stop_wordsList = list(stop_words)\n",
    "stop_wordsList.extend(['','-.','.,','(,','»,',').','-.','av.','».',\n",
    "                      '....','..','...','.....','()','(r).','—',')-«',\n",
    "                      '\".','-,','(-.',')-.','(©'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordsArticle = listArticle.split(' ')\n",
    "words = [word for word in wordsArticle if word not in stop_wordsList]\n",
    "countList = Counter(words).most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ans)', 464),\n",
       " ('fr.', 449),\n",
       " ('suisse', 346),\n",
       " ('deux', 279),\n",
       " ('genève', 212),\n",
       " ('tout', 194),\n",
       " ('sans', 189),\n",
       " ('fait', 183)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countList[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also try another method where we replace in the text each symbol that does not suit us. for that we need a dictionary, with only the most basic symbols.\n",
    "\n",
    "Then we also have to go through all the stopwords because otherwise we keep the word that do not bring information (le, la, les etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listPunct = list(string.punctuation)\n",
    "listPunct.remove(\"'\")\n",
    "listPunct.remove(\"-\")\n",
    "#we do not want to stick together all the words that\n",
    "#have an apostrophe (l'armée should not become larmée)\n",
    "stopDict = dict(zip(listPunct,['']*len(listPunct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictArticle = textArticle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in stopDict.items():\n",
    "    dictArticle = dictArticle.replace(k,v)\n",
    "\n",
    "dictCounter = [wordsDict for wordsDict in dictArticle.split(' ') if wordsDict not in stop_wordsList]\n",
    "countDict = Counter(dictCounter).most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ans', 735),\n",
       " ('suisse', 449),\n",
       " ('deux', 282),\n",
       " ('genève', 275),\n",
       " ('fait', 202),\n",
       " ('sans', 202),\n",
       " ('tout', 198),\n",
       " ('juin', 182),\n",
       " ('centre', 177),\n",
       " ('sep', 176)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countDict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for the 4 methods that we tested there is a clear tradeoff between speed and words. Going with nltk take 5 times more time but gives more accurate representation of words. Working brute force with the string data goes much faster, but does not give exactly the same results.\n",
    "\n",
    "The timing of each method (computed with the **%%timeit** magic function is summarized in the following table)\n",
    "\n",
    "\n",
    "\n",
    "| Method         |  NLTK  |   List  |  Dict  |\n",
    "|----------|------|------|------|\n",
    "| Time [s] | 9    | 1.5  | 1.5  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\").</th>\n",
       "      <th>$</th>\n",
       "      <th>%)</th>\n",
       "      <th>%,</th>\n",
       "      <th>%.</th>\n",
       "      <th>').</th>\n",
       "      <th>'s</th>\n",
       "      <th>(+</th>\n",
       "      <th>(.</th>\n",
       "      <th>(afp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NLTK word counts</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List Word count</th>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  \").    $   %)   %,   %.  ').   's   (+   (. (afp)\n",
       "NLTK word counts  NaN   31  NaN  NaN  NaN  NaN   27  NaN  NaN   NaN\n",
       "Dict word count   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN\n",
       "List Word count    18   29   18   17   30   18  NaN   36   33    36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFreq = pd.DataFrame(countFreq).transpose()\n",
    "dfFreq.columns = dfFreq.loc[0]\n",
    "dfFreq.drop(0,inplace=True)\n",
    "dfFreq.index = ['NLTK word counts']\n",
    "\n",
    "dfDict = pd.DataFrame(countDict).transpose()\n",
    "dfDict.columns = dfDict.loc[0]\n",
    "dfDict.drop(0,inplace=True)\n",
    "dfDict.index = ['Dict word count']\n",
    "\n",
    "dfList = pd.DataFrame(countList).transpose()\n",
    "dfList.columns = dfList.loc[0]\n",
    "dfList.drop(0,inplace=True)\n",
    "dfList.index = ['List Word count']\n",
    "\n",
    "pd.concat([dfFreq,dfDict,dfList],axis=0).ix[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cantonal</th>\n",
       "      <th>cantonale</th>\n",
       "      <th>cantons</th>\n",
       "      <th>cap</th>\n",
       "      <th>cap.</th>\n",
       "      <th>capital</th>\n",
       "      <th>car</th>\n",
       "      <th>caractère</th>\n",
       "      <th>carouge</th>\n",
       "      <th>carouge,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NLTK word counts</th>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List Word count</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>73</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cantonal cantonale cantons  cap cap. capital car caractère  \\\n",
       "NLTK word counts       24        19      25  115  NaN      44  59       NaN   \n",
       "Dict word count        24        19      25  115  NaN      44  59       NaN   \n",
       "List Word count        21        17      20   73   39      40  55        18   \n",
       "\n",
       "                 carouge carouge,  \n",
       "NLTK word counts      45      NaN  \n",
       "Dict word count       45      NaN  \n",
       "List Word count       23       18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dfFreq,dfDict,dfList],axis=0).ix[:,180:190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gibson,</th>\n",
       "      <th>giraudeau</th>\n",
       "      <th>global</th>\n",
       "      <th>gouvernement</th>\n",
       "      <th>gp</th>\n",
       "      <th>graf</th>\n",
       "      <th>grand</th>\n",
       "      <th>grande</th>\n",
       "      <th>grandes</th>\n",
       "      <th>grands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NLTK word counts</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>98</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>List Word count</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>98</td>\n",
       "      <td>55</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gibson, giraudeau global gouvernement   gp graf grand grande  \\\n",
       "NLTK word counts     NaN        29     31           58   27   31    98     56   \n",
       "Dict word count      NaN        29     31           58   27   31    98     56   \n",
       "List Word count       21       NaN     30           48  NaN   25    98     55   \n",
       "\n",
       "                 grandes grands  \n",
       "NLTK word counts      36     27  \n",
       "Dict word count       36     27  \n",
       "List Word count       36     27  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([dfFreq,dfDict,dfList],axis=0).ix[:,500:510]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see by looking into words that were counted that it seems nltk and dict word counting produce a result that is quite the same, and the list method is not good (no removal of commas, no removal of a lot of special signs). \n",
    "\n",
    "As we can see that given the similarity between NLTK and dict results, and given the fact that the dict method is 5 times as fast, we will implement a dict cleaning method in our data extraction pipeline.\n",
    "\n",
    "Below we show the euclidion distance petween nltk and dict Val and nltk and listVal to have a quantitative look at how they differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge = pd.concat([dfFreq,dfDict,dfList],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NLTK = np.nan_to_num(merge.loc['NLTK word counts'].values.astype(np.float))\n",
    "dictVal = np.nan_to_num(merge.loc['Dict word count'].values.astype(np.float))\n",
    "listVal = np.nan_to_num(merge.loc['List Word count'].values.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK and dict difference :  322.001552791\n",
      "NLTK and list difference :  1129.28517213\n"
     ]
    }
   ],
   "source": [
    "print('NLTK and dict difference : ', np.linalg.norm(NLTK-dictVal))\n",
    "print('NLTK and list difference : ', np.linalg.norm(NLTK-listVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that as expected NLTK and list are much more separated.\n",
    "\n",
    "Let's take a look at which words are not well understood in NLTK and dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juil.</th>\n",
       "      <th>juin</th>\n",
       "      <th>lac</th>\n",
       "      <th>lausanne</th>\n",
       "      <th>mai</th>\n",
       "      <th>ml</th>\n",
       "      <th>mois</th>\n",
       "      <th>nlg</th>\n",
       "      <th>no</th>\n",
       "      <th>oct.</th>\n",
       "      <th>sep.</th>\n",
       "      <th>sept.</th>\n",
       "      <th>swissca</th>\n",
       "      <th>travail</th>\n",
       "      <th>urgences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NLTK word counts</th>\n",
       "      <td>25</td>\n",
       "      <td>183</td>\n",
       "      <td>27</td>\n",
       "      <td>153</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>176</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>172</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>129</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>182</td>\n",
       "      <td>23</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>175</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>128</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 juil. juin lac lausanne mai  ml mois nlg  no oct. sep. sept.  \\\n",
       "NLTK word counts    25  183  27      153  60  21  176  55  53   48  172    19   \n",
       "Dict word count    NaN  182  23      150  59  20  175  52  52  NaN  NaN   NaN   \n",
       "\n",
       "                 swissca travail urgences  \n",
       "NLTK word counts      38     129       40  \n",
       "Dict word count       37     128       36  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = NLTK - dictVal\n",
    "dfDiff = merge.ix[0:2,diff>0]\n",
    "dfDiff.ix[:,20:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sep.</th>\n",
       "      <th>sept.</th>\n",
       "      <th>swissca</th>\n",
       "      <th>travail</th>\n",
       "      <th>urgences</th>\n",
       "      <th>ville</th>\n",
       "      <th>yen</th>\n",
       "      <th>~</th>\n",
       "      <th>—</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NLTK word counts</th>\n",
       "      <td>172</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>129</td>\n",
       "      <td>40</td>\n",
       "      <td>137</td>\n",
       "      <td>55</td>\n",
       "      <td>34</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>128</td>\n",
       "      <td>36</td>\n",
       "      <td>119</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sep. sept. swissca travail urgences ville yen    ~    —\n",
       "NLTK word counts  172    19      38     129       40   137  55   34   85\n",
       "Dict word count   NaN   NaN      37     128       36   119  54  NaN  NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDiff.ix[:,30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['$', ''s', '-.', '=', '^', 'allemand', 'ans', 'aug.', 'avant', 'banque',\n",
       "       'chf', 'd'affaires', 'dec.', 'entreprises', 'france', 'fériés', 'gen.',\n",
       "       'genève', 'inc.', 'jan.', 'juil.', 'juin', 'lac', 'lausanne', 'mai',\n",
       "       'ml', 'mois', 'nlg', 'no', 'oct.', 'sep.', 'sept.', 'swissca',\n",
       "       'travail', 'urgences', 'ville', 'yen', '~', '—'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.ix[:,diff>0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this analysis we see two things, first that there are not a lot of words where a difference can be found, and when there is a difference it is not very large, so by using the dict method we only gain speed without loosing a lot of information.\n",
    "\n",
    "The next two cells summarize the fact the we do not loose a lot of inforamtion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0      1122\n",
       " 1.0        14\n",
       "-18.0        8\n",
       " 4.0         4\n",
       "-1.0         3\n",
       " 3.0         2\n",
       " 25.0        2\n",
       "-27.0        2\n",
       " 22.0        2\n",
       "-71.0        1\n",
       "-2.0         1\n",
       " 2.0         1\n",
       " 18.0        1\n",
       " 34.0        1\n",
       " 5.0         1\n",
       "-19.0        1\n",
       "-20.0        1\n",
       "-14.0        1\n",
       " 39.0        1\n",
       " 27.0        1\n",
       " 31.0        1\n",
       "-3.0         1\n",
       "-28.0        1\n",
       " 19.0        1\n",
       " 28.0        1\n",
       " 71.0        1\n",
       "-35.0        1\n",
       "-23.0        1\n",
       " 23.0        1\n",
       "-49.0        1\n",
       " 40.0        1\n",
       "-48.0        1\n",
       " 48.0        1\n",
       "-6.0         1\n",
       "-176.0       1\n",
       " 172.0       1\n",
       "-16.0        1\n",
       " 85.0        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(diff).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sep.</th>\n",
       "      <th>—</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NLTK word counts</th>\n",
       "      <td>172</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sep.    —\n",
       "NLTK word counts  172   85\n",
       "Dict word count   NaN  NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge.ix[0:2,diff>80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally we have to set the index as a datetime to be able to plot correctly in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans</th>\n",
       "      <th>suisse</th>\n",
       "      <th>deux</th>\n",
       "      <th>genève</th>\n",
       "      <th>fait</th>\n",
       "      <th>sans</th>\n",
       "      <th>tout</th>\n",
       "      <th>juin</th>\n",
       "      <th>centre</th>\n",
       "      <th>sep</th>\n",
       "      <th>...</th>\n",
       "      <th>tandis</th>\n",
       "      <th>important</th>\n",
       "      <th>banco</th>\n",
       "      <th>l'emploi</th>\n",
       "      <th>laisse</th>\n",
       "      <th>république</th>\n",
       "      <th>ind</th>\n",
       "      <th>quinze</th>\n",
       "      <th>présidence</th>\n",
       "      <th>liffe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dict word count</th>\n",
       "      <td>735</td>\n",
       "      <td>449</td>\n",
       "      <td>282</td>\n",
       "      <td>275</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>198</td>\n",
       "      <td>182</td>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                ans suisse deux genève fait sans tout juin centre  sep  ...   \\\n",
       "Dict word count  735    449  282    275  202  202  198  182    177  176  ...    \n",
       "\n",
       "0               tandis important banco l'emploi laisse république ind quinze  \\\n",
       "Dict word count     18        18    18       18     18         18  18     18   \n",
       "\n",
       "0               présidence liffe  \n",
       "Dict word count         18    18  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = pd.to_datetime('1997/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfDict.index = [date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans</th>\n",
       "      <th>suisse</th>\n",
       "      <th>deux</th>\n",
       "      <th>genève</th>\n",
       "      <th>fait</th>\n",
       "      <th>sans</th>\n",
       "      <th>tout</th>\n",
       "      <th>juin</th>\n",
       "      <th>centre</th>\n",
       "      <th>sep</th>\n",
       "      <th>...</th>\n",
       "      <th>tandis</th>\n",
       "      <th>important</th>\n",
       "      <th>banco</th>\n",
       "      <th>l'emploi</th>\n",
       "      <th>laisse</th>\n",
       "      <th>république</th>\n",
       "      <th>ind</th>\n",
       "      <th>quinze</th>\n",
       "      <th>présidence</th>\n",
       "      <th>liffe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-01-01</th>\n",
       "      <td>735</td>\n",
       "      <td>449</td>\n",
       "      <td>282</td>\n",
       "      <td>275</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>198</td>\n",
       "      <td>182</td>\n",
       "      <td>177</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0           ans suisse deux genève fait sans tout juin centre  sep  ...   \\\n",
       "1997-01-01  735    449  282    275  202  202  198  182    177  176  ...    \n",
       "\n",
       "0          tandis important banco l'emploi laisse république ind quinze  \\\n",
       "1997-01-01     18        18    18       18     18         18  18     18   \n",
       "\n",
       "0          présidence liffe  \n",
       "1997-01-01         18    18  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
